#!/usr/bin/env python
#coding=utf-8

'''
AMRDataset reads the file generated by preprocessing.sh and it generates a AMRSentence instance for each sentence,
containing all information necessary to the parser.
@author: Marco Damonte (m.damonte@sms.ed.ac.uk)
@since: 3-10-16
'''

import re
from alignments import Alignments as Alignments
import sys
import amrevaluation.smatch.amr_edited as amrannot
sys.path.append("..")
reload(sys)
sys.setdefaultencoding('utf8')

class AMRSentence:
    def __init__(self, tokens, pos, lemmas, nes, dependencies, variables = None, relations = None, graph = None, alignments = None):
        self.tokens = tokens
        self.pos = pos
        self.lemmas = lemmas
        self.nes = nes
        self.dependencies = dependencies
        if variables is not None:
            self.variables = [(str(k),str(variables[k])) for k in variables] 
        if relations is not None:
            self.relations = [r for r in relations if r[0] != r[2]]
        self.graph = graph
        self.alignments = alignments

class AMRDataset:
    def _var2concept(self, amr):
        v2c = {}
        for n, v in zip(amr.nodes, amr.node_values):
            v2c[n] = v
        return v2c

    def __init__(self, prefix, amrs, normalize = True):
        self.normalize = normalize
        self.sentences = []

        alltokens, allpos, alllemmas, allnes, alldependencies = self._loadFromFile(prefix + ".out")
        if amrs:
            allgraphs = open(prefix + ".graphs").read().split("\n\n")
            a = Alignments(prefix + ".alignments", allgraphs)
            allalignments = a.alignments

            for graph, alignments, dependencies, tokens, pos, lemmas, nes in zip(allgraphs, allalignments, alldependencies, alltokens, allpos, alllemmas, allnes):
                graph = graph.strip()
                amr = amrannot.AMR.parse_AMR_line(graph.replace("\n",""), False)
                variables = {}
                for n, v in zip(amr.nodes, amr.node_values):
                    variables[n] = v
                role_triples = amr.get_triples3()
                relations = []
                for (var1,label,var2) in role_triples:
                    if label == "TOP":
                        relations.append(("TOP",":top",var1))
                    else:
                        relations.append((str(var1),":" + str(label),str(var2)))
                self.sentences.append(AMRSentence(tokens, pos, lemmas, nes, dependencies, variables, relations, graph, alignments))
        else:
            for dependencies, tokens, pos, lemmas, nes in zip(alldependencies, alltokens, allpos, alllemmas, allnes):
                self.sentences.append(AMRSentence(tokens, pos, lemmas, nes, dependencies))


    def getSent(self, index):
        return self.sentences[index]

    def getAllSents(self):
        return self.sentences

    def _loadFromFile(self, stanfordOutput):
        alltokens = []
        allpos = []
        alllemmas = []
        allnes = []
        alldependencies = []
        for lines in open(stanfordOutput, 'r').read().split("\n\n"):
            if lines.strip() == "":
                break
            tokens = []
            lemmas = []
            nes = []
            pos = []
            dependencies = []
            
            for line in lines.split("\n"):
                fields = line.split("\t")
                if line.strip() == "":
                    break
                tokens.append(fields[1])
                lemmas.append(fields[2])
                if fields[6].split("-")[1] != "":
                    nes.append(fields[6].split("-")[1])
                else:
                    nes.append("O")
                pos.append(fields[4])
                if int(fields[9]) == 0:
                    dependencies.append((int(fields[0]) - 1, fields[10], 0))
                else:
                    dependencies.append((int(fields[0]) - 1, fields[10], int(fields[9]) - 1))
                    
            #very messy piece of code to handle corenlp normalization (for dates, currencies, etc)
            tokens2 = []
            lemmas2 = []
            nes2 = []
            for token, lemma, ne in zip(tokens, lemmas, nes):
                nesplit = ne.split()
                if len(nesplit) > 1:
                    mne = re.match("^([a-zA-Z\%\>\<\$\~\=]*)([0-9\.]*.*)", nesplit[1][25:].encode('ascii', 'ignore'))
                else:
                    mne = None
                if nesplit[0] == "DATE" and re.match("^(\d{4}|XXXX)(-\d{2})?(-\d{2})?$",nesplit[1][25:]) is not None:
                    norm = nesplit[1][25:]
                    lastnorm = norm
                    tokens2.append(norm)
                    lemmas2.append(norm)
                    nes2.append(nesplit[0])

                elif (nesplit[0] == "MONEY" or nesplit[0] == "PERCENT") and self.normalize and len(nesplit) == 2 and mne is not None:
                    [name, norm] = nesplit
                    curr = mne.groups()[0]
                    norm = mne.groups()[1]
                    curr = curr.replace("<","").replace(">","").replace("~","").replace("=","")
                    if curr == "$":
                        curr = "dollar"
                    if curr == "":
                        w = nesplit[1][25:].replace("<","").replace(">","").replace("~","").replace("=","")
                        if w.startswith(u"\u00A5"):
                            curr = "yen"
                        elif w.startswith(u"\u5143"):
                            curr = "yuan"
                        elif w.startswith(u"\u00A3"):
                            curr = "pound"
                        elif w.startswith(u"\u20AC"):
                            curr = "euro"
                        else:
                            curr = "NULL"

                    m = re.match("([0-9\.][0-9\.]*)E([0-9][0-9]*)$",norm)
                    if m is not None:
                        n = m.groups()[0]
                        z = "".join(["0"]*int(m.groups()[1]))
                        norm = format(float(n)*float("1"+z), ".32f")
                        norm = re.sub("\.00*$","",norm)
                    if token.endswith(".0") == False:
                        norm = re.sub("\.0$","",norm)
                    if token.replace(",","").replace(".","").isdigit() == False and lastnorm is not None:
                        norm = "," 
                        token = ","
                        name = "O"
                    lastnorm = norm
                    if norm == ",":
                        tokens2.append(norm)
                    else:
                        tokens2.append(norm + "_" + curr)
                    lemmas2.append(token)
                    nes2.append(name)
                elif self.normalize and len(nesplit) == 2 and re.match("^[0-9].*", nesplit[1][25:]) is not None: #numbers
                    [name, norm] = nesplit
                    norm = norm[25:]
                    m = re.match("([0-9\.][0-9\.]*)E([0-9][0-9]*)$",norm)
                    if m is not None:
                        n = m.groups()[0]
                        z = "".join(["0"]*int(m.groups()[1]))
                        norm = str(float(n)*int("1"+z))
                    if token.endswith(".0") == False:
                        norm = re.sub("\.0$","",norm)
                    if token.replace(",","").replace(".","").isdigit() == False and lastnorm is not None:
                        norm = "," 
                        token = ","
                        name = "O"
                    lastnorm = norm
                    tokens2.append(norm)
                    lemmas2.append(token)
                    nes2.append(name)
                else:
                    lastnorm = None
                    tokens2.append(token)
                    lemmas2.append(lemma)
                    nes2.append(nesplit[0])
            alltokens.append(tokens2)
            allpos.append(pos)
            alllemmas.append(lemmas2)
            allnes.append(nes2)
            alldependencies.append(dependencies)
        return (alltokens, allpos, alllemmas, allnes, alldependencies)
